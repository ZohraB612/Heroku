{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "519959d7",
   "metadata": {},
   "source": [
    "# Digit Recognition Using the MNIST Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f1864e",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05d38a6",
   "metadata": {},
   "source": [
    "This notebook aims to build a model to classify handwritten digits using the MNIST dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02804787",
   "metadata": {},
   "source": [
    "## 2. About the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0e0fc20",
   "metadata": {},
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a large database of handwritten digits that is commonly used for training and testing in the field of machine learning. The dataset contains 60,000 training images and 10,000 testing images. Each image is a 28x28 grayscale image, associated with a label from 0 to 9."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d0abf0",
   "metadata": {},
   "source": [
    "## 3. Data loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5ce7767",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries and loading the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b46d20b",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd9bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ac9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5dd36a0",
   "metadata": {},
   "source": [
    "## 4. Data exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b6d7b52",
   "metadata": {},
   "source": [
    "Let's explore what these images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe5eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea1445dd",
   "metadata": {},
   "source": [
    "## 5. Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a415baa",
   "metadata": {},
   "source": [
    "We need to normalize our pixel values (between 0 and 255) to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8cc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the Random Forest classifier to the training data\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted model to make predictions on the test data\n",
    "predictions = forest.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c450134e",
   "metadata": {},
   "source": [
    "## 6. Model building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "040ef54e",
   "metadata": {},
   "source": [
    "Let's build a simple neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ffd05b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the model\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "\n",
    "# Save the model to disk\n",
    "pickle.dump(forest, open('model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30eb6ae8",
   "metadata": {},
   "source": [
    "We'll compile the model with an appropriate optimizer and loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f324c89a",
   "metadata": {},
   "source": [
    "## 8. Model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c68fbdc9",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0650cbf",
   "metadata": {},
   "source": [
    "## 9. Save the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7ea937",
   "metadata": {},
   "source": [
    "After training, we can save our model for future use. Let's save it using TensorFlow's saved model format.\n",
    "This function will create a directory named mnist_model in the current working directory, and will contain the architecture, optimizer, and learned parameters of our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b8617c8",
   "metadata": {},
   "source": [
    "## 10. Model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f05051",
   "metadata": {},
   "source": [
    "Finally, let's evaluate the performance of our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1851163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "Test accuracy: 0.9834\n",
      "Precision: 0.9833615723771738\n",
      "Recall: 0.9831984222663305\n",
      "F1-score: 0.9832697916031774\n"
     ]
    }
   ],
   "source": [
    "# # Get the predicted labels for the test set\n",
    "# test_predictions = model.predict(test_images)\n",
    "# test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# # Calculate precision\n",
    "# precision = precision_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# # Calculate recall\n",
    "# recall = recall_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# # Calculate F1-score\n",
    "# f1 = f1_score(test_labels, test_predictions, average='macro')\n",
    "\n",
    "# print('Test accuracy:', accuracy)\n",
    "# print('Precision:', precision)\n",
    "# print('Recall:', recall)\n",
    "# print('F1-score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
